{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tensorflow / ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Utility\n",
    "import time\n",
    "\n",
    "# Local\n",
    "from asteroid_integrate import load_ast_elt\n",
    "from candidate_element import orbital_element_batch, perturb_elts, random_elts\n",
    "from ztf_data import load_ztf_nearest_ast, calc_hit_freq, load_ztf_batch, make_ztf_batch\n",
    "from asteroid_model import AsteroidPosition, AsteroidDirection\n",
    "from asteroid_search_layers import CandidateElements, TrajectoryScore\n",
    "from asteroid_search_model import AsteroidSearchModel, make_adam_opt\n",
    "from astro_utils import deg2dist, dist2deg, dist2sec\n",
    "from tf_utils import Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliases\n",
    "keras = tf.keras\n",
    "\n",
    "# Constants\n",
    "dtype = tf.float32\n",
    "dtype_np = np.float32\n",
    "space_dims = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ZTF Data and Batch of Orbital Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load orbital elements for known asteroids\n",
    "ast_elt = load_ast_elt()\n",
    "\n",
    "# Number of asteroids\n",
    "N_ast = ast_elt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ztf nearest asteroid data\n",
    "ztf_ast = load_ztf_nearest_ast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asteroid numbers and hit counts\n",
    "ast_num, hit_count = calc_hit_freq(ztf=ztf_ast, thresh_sec=2.0)\n",
    "\n",
    "# Sort the hit counts in descending order and find the top batch_size\n",
    "idx = np.argsort(hit_count)[::-1]\n",
    "\n",
    "# Extract the asteroid number and hit count for this batch\n",
    "ast_num_best = ast_num[idx]\n",
    "hit_count_best = hit_count[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 64\n",
    "elt_batch_size = batch_size\n",
    "\n",
    "# Batch of unperturbed elements\n",
    "elts_ast = orbital_element_batch(ast_nums=ast_num_best[0:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elts_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturb orbital elements\n",
    "sigma_a = 0.0 \n",
    "sigma_e = 0.0 \n",
    "sigma_f_deg = 0.1\n",
    "sigma_Omega_deg = 0.0\n",
    "sigma_omega_deg = 0.0\n",
    "mask_pert = None\n",
    "random_seed = 42\n",
    "\n",
    "elts_pert = perturb_elts(elts_ast, sigma_a=sigma_a, sigma_e=sigma_e, sigma_f_deg=sigma_f_deg, \n",
    "                         sigma_Omega_deg=sigma_Omega_deg, sigma_omega_deg=sigma_omega_deg,\n",
    "                         mask_pert=mask_pert, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elts_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random elements\n",
    "elts_rand = random_elts(element_id_start=0, size=elt_batch_size, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elts_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches of ZTF Data vs. Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments to make_ztf_batch\n",
    "thresh_deg = 1.0\n",
    "near_ast = False\n",
    "regenerate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unperturbed element batch\n",
    "ztf_elt_ast = load_ztf_batch(elts=elts_ast, thresh_deg=thresh_deg, near_ast=near_ast, regenerate=regenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load perturbed element batch\n",
    "ztf_elt_pert = load_ztf_batch(elts=elts_pert, thresh_deg=thresh_deg, near_ast=near_ast, regenerate=regenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random element batch\n",
    "ztf_elt_rand = load_ztf_batch(elts=elts_rand, thresh_deg=thresh_deg, near_ast=near_ast, regenerate=regenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_elt_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review hits\n",
    "mask = ztf_elt_ast.is_hit\n",
    "ztf_elt_ast[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_elt_ast.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias ztf_elt_ast to ztf_elt\n",
    "ztf_elt = ztf_elt_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build numpy array of times\n",
    "ts_np = ztf_elt.mjd.values.astype(dtype_np)\n",
    "\n",
    "# Get observation count per element\n",
    "row_lengths_np = ztf_elt.element_id.groupby(ztf_elt.element_id).count().values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review results\n",
    "element_id_best = ast_num_best[0]\n",
    "mask = (ztf_elt.element_id == element_id_best)\n",
    "hits_best = np.sum(ztf_elt[mask].is_hit)\n",
    "hit_rate_best = np.mean(ztf_elt[mask].is_hit)\n",
    "rows_best = np.sum(mask)\n",
    "s_sec_min = np.min(ztf_elt[mask].s_sec)\n",
    "idx = np.argmin(ztf_elt.s)\n",
    "ztf_id = ztf_elt.ztf_id[idx]\n",
    "# ztf_elt[mask].iloc[idx:idx+1]\n",
    "print(f'Best asteroid has element_id = {element_id_best}')\n",
    "print(f'Hit count: {hits_best} / {rows_best} observations')\n",
    "print(f'Hit rate : {hit_rate_best:8.6f}')\n",
    "print(f'Closest hit: {s_sec_min:0.3f} arc seconds')\n",
    "# ztf_elt[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Asteroid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional arguments for asteroid search models\n",
    "site_name = 'palomar'\n",
    "h = 0.01\n",
    "R_deg = 1.0\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 2.0E-4\n",
    "clipnorm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build asteroid search model\n",
    "model = AsteroidSearchModel(\n",
    "        elts=elts_ast, ztf_elt=ztf_elt, site_name=site_name,\n",
    "        thresh_deg=thresh_deg, h=h, R_deg=R_deg,\n",
    "        learning_rate=learning_rate, clipnorm=clipnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy inputs for search model; any array with shape [elt_batch_size,] is good\n",
    "x = np.ones(elt_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on unperturbed elements\n",
    "log_like, elts_tf, mixture = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize log likelihood on unperturbed elements\n",
    "log_like_tot = np.sum(log_like)\n",
    "log_like_mean = np.mean(log_like)\n",
    "log_like_std = np.std(log_like)\n",
    "\n",
    "# Report on unperturbed elements\n",
    "print(f'Log likelihood:')\n",
    "print(f'Total: {log_like_tot:8.2f}')\n",
    "print(f'Mean: {log_like_mean:8.2f}')\n",
    "print(f'Std : {log_like_std:8.2f}')\n",
    "print(f'First 5:')\n",
    "print(log_like[0:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model on Unperturbed Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.current_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.restore_best_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.current_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 1\n",
    "samples_per_epoch = batch_size*steps_per_epoch\n",
    "x_trn = tf.ones(samples_per_epoch, dtype=dtype)\n",
    "# model.recompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_trn, batch_size=batch_size, epochs=1, steps_per_epoch=steps_per_epoch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.search_adaptive(max_batches=10000, \n",
    "                      batches_per_epoch=20,\n",
    "                      epochs_per_episode=10,\n",
    "                      verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0, restore_best_weights=True, verbose=True)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training length: epochs, steps per epoch\n",
    "epochs = 10\n",
    "steps_per_epoch = 200\n",
    "samples_per_epoch = steps_per_epoch * batch_size\n",
    "x_trn = np.ones(samples_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate before training\n",
    "model.evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review learning rate\n",
    "print(f'learning_rate = {model.learning_rate}')\n",
    "print(f'clipnorm      = {model.clipnorm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "hist = model.fit(x=x_trn, batch_size=batch_size, epochs=20, steps_per_epoch=steps_per_epoch, \n",
    "                 callbacks=callbacks, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=x_trn, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, \n",
    "                 callbacks=callbacks, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "log_like, elts_tf, mixture = model.predict(x)\n",
    "\n",
    "# Report mixture\n",
    "h = mixture[:, 0]\n",
    "lam = mixture[:, 1]\n",
    "h_mean = np.mean(h)\n",
    "lam_mean = np.mean(lam)\n",
    "print(f'h_mean      = {h_mean:8.6f}')\n",
    "print(f'lambda_mean = {lam_mean:6.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.elements.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build asteroid search model\n",
    "model = make_model_asteroid_search(\n",
    "        elts=elts_ast, ztf_elt=ztf_elt, site_name=site_name,\n",
    "        thresh_deg=thresh_deg, h=h, R_deg=R_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model adaptively\n",
    "ast_search_adaptive(model,\n",
    "                    learning_rate=1.0E-4, clipnorm=1.0,\n",
    "                    max_epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second (tune-up) adaptive training\n",
    "ast_search_adaptive(model,\n",
    "                    learning_rate=None, clipnorm=None,\n",
    "                    max_epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "thresh_s = keras.backend.constant(deg2dist(thresh_deg))\n",
    "thresh_s2 = keras.backend.constant(thresh_s**2)\n",
    "thresh_z = keras.backend.constant(np.sqrt(1.0 - thresh_s2/2.0))\n",
    "\n",
    "# Report thresholds\n",
    "print(f'Thresholds:')\n",
    "print(f's  : {thresh_s:6.2e}')\n",
    "print(f's2 : {thresh_s2:6.2e}')\n",
    "# print(f'z  : {thresh_z:10.8f}')\n",
    "print(f'1-z: {1.0 - thresh_z:6.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asteroid_model import AsteroidPosition, AsteroidDirection\n",
    "from asteroid_search_model import OrbitalElements, TrajectoryScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dims = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias inputs\n",
    "elts = elts_ast\n",
    "ztf_elt = ztf_elt_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed directions; extract from ztf_elt DataFrame\n",
    "cols_u_obs = ['ux', 'uy', 'uz']\n",
    "u_obs_np = ztf_elt[cols_u_obs].values.astype(dtype_np)    \n",
    "\n",
    "# Set of trainable weights with candidate orbital elements; initialize according to elts\n",
    "elements_layer = OrbitalElements(elts=elts, h=h, lam=lam, name='candidates')\n",
    "\n",
    "# Extract the candidate elements and mixture parameters; pass dummy inputs to satisfy keras Layer API\n",
    "a, e, inc, Omega, omega, f, epoch, h, lam = elements_layer(inputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The orbital elements; stack to shape (elt_batch_size, 7)\n",
    "elts_tf = tf.stack(values=[a, e, inc, Omega, omega, f, epoch], axis=1, name='elts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted direction\n",
    "direction_layer = AsteroidDirection(ts_np=ts_np, row_lengths_np=row_lengths_np, \n",
    "                                    site_name=site_name, name='direction_layer')\n",
    "\n",
    "# Calibration arrays (flat)\n",
    "cols_q_ast = ['qx', 'qy', 'qz']\n",
    "cols_v_ast = ['vx', 'vy', 'vz']\n",
    "q_ast = ztf_elt[cols_q_ast].values.astype(dtype_np)\n",
    "v_ast = ztf_elt[cols_v_ast].values.astype(dtype_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run calibration\n",
    "direction_layer.q_layer.calibrate(elts=elts, q_ast=q_ast, v_ast=v_ast)\n",
    "\n",
    "# Tensor of predicted directions\n",
    "u_pred, r_pred = direction_layer(a, e, inc, Omega, omega, f, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score layer for these observations\n",
    "score_layer = TrajectoryScore(row_lengths_np=row_lengths_np, u_obs_np=u_obs_np,\n",
    "                              thresh_deg=thresh_deg, name='score_layer')\n",
    "\n",
    "# Compute the log likelihood by element from the predicted direction and mixture model parameters\n",
    "log_like = score_layer(u_pred, h=h, lam=lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check selected row: row 11 has ztf_id = 341737, elt_id 733 (first hit)\n",
    "u_pred[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shapes\n",
    "data_size = keras.backend.constant(value=tf.reduce_sum(row_lengths_np), dtype=tf.int32)\n",
    "row_lengths = keras.backend.constant(value=row_lengths_np, shape=row_lengths_np.shape, dtype=tf.int32)\n",
    "u_shape = (data_size, space_dims,)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save u_obs\n",
    "u_obs = keras.backend.constant(value=u_obs_np, shape=u_shape, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance\n",
    "du = u_pred - u_obs\n",
    "s2 = tf.reduce_sum(tf.square(du), axis=(-1), name='s2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include terms where z2 is within the threshold distance^2\n",
    "is_close = tf.math.less(s2, thresh_s2, name='is_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_close[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative distance v on data inside threshold\n",
    "v = tf.divide(tf.boolean_mask(tensor=s2, mask=is_close), thresh_s2, name='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row_lengths, for close observations only\n",
    "# is_close_r = tf.RaggedTensor.from_row_lengths(values=is_close, row_lengths=self.row_lengths, name='is_close_r')\n",
    "ragged_map_func = lambda x : tf.RaggedTensor.from_row_lengths(values=x, row_lengths=row_lengths)\n",
    "is_close_r = tf.keras.layers.Lambda(function=ragged_map_func, name='is_close_r')(is_close)\n",
    "row_lengths_close = tf.reduce_sum(tf.cast(is_close_r, tf.int32), axis=1, name='row_lengths_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_lengths_close[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of parameters\n",
    "close_size = tf.reduce_sum(row_lengths_close)\n",
    "param_shape = (close_size,)\n",
    "\n",
    "# Upsample h and lambda\n",
    "h_rep = tf.repeat(input=h, repeats=row_lengths_close, name='h_rep')\n",
    "h_vec = tf.reshape(tensor=h_rep, shape=param_shape, name='h_vec')\n",
    "lam_rep = tf.repeat(input=lam, repeats=row_lengths_close, name='lam_rep')\n",
    "lam_vec = tf.reshape(tensor=lam_rep, shape=param_shape, name='lam_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vec[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_vec[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability according to mixture model\n",
    "emlx = tf.exp(-lam_vec * v, name='p_hit_cond') \n",
    "p_hit_cond_num = tf.multiply(emlx, lam_vec)\n",
    "p_hit_cond_den = tf.subtract(1.0, tf.exp(-lam_vec))\n",
    "p_hit_cond = tf.divide(p_hit_cond_num, p_hit_cond_den)\n",
    "p_hit = tf.multiply(h_vec, p_hit_cond, name='p_hit')\n",
    "p_miss = tf.subtract(1.0, h_vec, name='p_miss')\n",
    "p = tf.add(p_hit, p_miss, name='p')\n",
    "log_p_flat = keras.layers.Activation(tf.math.log, name='log_p_flat')(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_flat[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hit_cond[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kepler]",
   "language": "python",
   "name": "conda-env-kepler-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
